{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00506630-241a-413d-9cfd-ae1008a02f89",
   "metadata": {},
   "source": [
    "#### Similarity Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa655a-bcd5-43e2-9d24-d2e9edc74332",
   "metadata": {},
   "source": [
    "---\n",
    "######  - [Reading the data set](#Reading-the-data-set)\n",
    "######  - [Combining data for text similarity](#Combining-data-for-text-similarity)\n",
    "######  - [Overall TFIDF Cosine Similarity](#Overall-TFIDF-Cosine-Similarity)\n",
    "######  - [Pariwise TFIDF Cosine Similarity](#Pariwise-TFIDF-Cosine-Similarity)\n",
    "######  - [Writing the dataset](#Writing-the-dataset)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199934c0-e1c0-4ca5-9265-bf7879249690",
   "metadata": {},
   "source": [
    "#### Reading the data set\n",
    "######  - [_Click here to move back to index_](#Similarity-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce0b8a0-983c-49f3-82e7-440c19d0bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')  # Use 'src' if it's in the same folder as the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3d7217f-ca01-4051-b76f-55cc62fd7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocessing import load_data\n",
    "\n",
    "#Reading preprocessed dataset of all TV series\n",
    "\n",
    "series_1 = load_data('data/processed/processed_series_1.csv')\n",
    "series_2 = load_data('data/processed/processed_series_2.csv')\n",
    "series_3 = load_data('data/processed/processed_series_3.csv')\n",
    "series_4 = load_data('data/processed/processed_series_4.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abc1c7-93e6-4ced-b9d4-f3c103b76359",
   "metadata": {},
   "source": [
    "#### Combining data for text similarity\n",
    "######  - [_Click here to move back to index_](#Similarity-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9ddd203-6dee-44ea-be36-bcaa89d2592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [series_1, series_2, series_3, series_4]\n",
    "series_names = ['Friends', 'Game of Thrones', 'The Office', 'The Big Bang Theory']\n",
    "columns = ['series', 'character', 'season', 'season_episode', 'dialogue', 'dialogue_preprocessed', 'dialogue_length']\n",
    "final_dfs = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    df['series'] = series_names[i]\n",
    "\n",
    "    # Find top 6 characters based on total dialogue length\n",
    "    top_chars = (\n",
    "        df.groupby('character')['dialogue_length']\n",
    "        .sum()\n",
    "        .nlargest(6)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    # Filter and keep only necessary columns\n",
    "    df_top = df[df['character'].isin(top_chars)][['series', 'character', 'season', 'season_episode', 'dialogue', 'dialogue_preprocessed']]\n",
    "    final_dfs.append(df_top)\n",
    "\n",
    "# Combine all\n",
    "combined_df = pd.concat(final_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1db6b73a-11e9-43a1-b0b6-f0f7523dc653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>character</th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136038</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>10</td>\n",
       "      <td>10x24</td>\n",
       "      <td>Uh, breakfast yes, lunch no. I did have a cou...</td>\n",
       "      <td>uh breakfast yes lunch cough drop really ride ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136039</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>10</td>\n",
       "      <td>10x24</td>\n",
       "      <td>How thoughtful. Thank you.</td>\n",
       "      <td>thoughtful thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136040</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>10</td>\n",
       "      <td>10x24</td>\n",
       "      <td>And I with you. Question, are you seeking a r...</td>\n",
       "      <td>question seeking romantic relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136041</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>10</td>\n",
       "      <td>10x24</td>\n",
       "      <td>Well, that would raise a number of problems. ...</td>\n",
       "      <td>well would raise number problem colleague curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136042</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>10</td>\n",
       "      <td>10x24</td>\n",
       "      <td>(Knock, knock, knock) Amy. (Knock, knock, kno...</td>\n",
       "      <td>knock knock knock amy knock knock knock amy kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     series character  season season_episode  \\\n",
       "136038  The Big Bang Theory   Sheldon      10          10x24   \n",
       "136039  The Big Bang Theory   Sheldon      10          10x24   \n",
       "136040  The Big Bang Theory   Sheldon      10          10x24   \n",
       "136041  The Big Bang Theory   Sheldon      10          10x24   \n",
       "136042  The Big Bang Theory   Sheldon      10          10x24   \n",
       "\n",
       "                                                 dialogue  \\\n",
       "136038   Uh, breakfast yes, lunch no. I did have a cou...   \n",
       "136039                         How thoughtful. Thank you.   \n",
       "136040   And I with you. Question, are you seeking a r...   \n",
       "136041   Well, that would raise a number of problems. ...   \n",
       "136042   (Knock, knock, knock) Amy. (Knock, knock, kno...   \n",
       "\n",
       "                                    dialogue_preprocessed  \n",
       "136038  uh breakfast yes lunch cough drop really ride ...  \n",
       "136039                                   thoughtful thank  \n",
       "136040             question seeking romantic relationship  \n",
       "136041  well would raise number problem colleague curr...  \n",
       "136042  knock knock knock amy knock knock knock amy kn...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336058bb-3faa-4d74-9b52-8653436b0219",
   "metadata": {},
   "source": [
    "#### Overall TFIDF Cosine Similarity\n",
    "######  - [_Click here to move back to index_](#Similarity-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b5967da-2dc9-4694-a36f-ea41b84284af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Group by series and character\n",
    "combined_df = combined_df[['series', 'character', 'dialogue']].dropna()\n",
    "overall_dialogues = combined_df.groupby(['series', 'character'])['dialogue'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Create MultiIndex for rows and columns\n",
    "multi_index = pd.MultiIndex.from_frame(overall_dialogues[['series', 'character']])\n",
    "\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(overall_dialogues['dialogue'])\n",
    "\n",
    "# Similarity matrix\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Final DataFrame with MultiIndex\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=multi_index, columns=multi_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30264162-4d3d-4d74-8cde-ccdef7fbf723",
   "metadata": {},
   "source": [
    "#### Pariwise TFIDF Cosine Similarity\n",
    "######  - [_Click here to move back to index_](#Similarity-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f531c556-ba44-457b-ba3c-aa87ef355d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare your data\n",
    "dialogue_df = combined_df[['series', 'character', 'dialogue']].dropna()\n",
    "dialogue_df = dialogue_df[dialogue_df['dialogue'].str.strip() != ''].reset_index(drop=True)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(dialogue_df['dialogue'])\n",
    "\n",
    "# Use Nearest Neighbors to get top 5 most similar for each dialogue\n",
    "nbrs = NearestNeighbors(n_neighbors=6, metric='cosine', algorithm='brute').fit(tfidf_matrix)\n",
    "distances, indices = nbrs.kneighbors(tfidf_matrix)\n",
    "\n",
    "# Store results (excluding self-match at index 0)\n",
    "results = []\n",
    "for i, (dists, idxs) in enumerate(zip(distances, indices)):\n",
    "    for dist, j in zip(dists[1:], idxs[1:]):  # skip self\n",
    "        similarity = 1 - dist\n",
    "        if similarity >= 0.7:\n",
    "            results.append({\n",
    "                'Dialogue_1': dialogue_df.loc[i, 'dialogue'],\n",
    "                'Character_1': dialogue_df.loc[i, 'character'],\n",
    "                'Series_1': dialogue_df.loc[i, 'series'],\n",
    "                'Dialogue_2': dialogue_df.loc[j, 'dialogue'],\n",
    "                'Character_2': dialogue_df.loc[j, 'character'],\n",
    "                'Series_2': dialogue_df.loc[j, 'series'],\n",
    "                'Cosine_Similarity': similarity\n",
    "            })\n",
    "\n",
    "similarity_top_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c1bf5-c254-4d7e-87ce-b027e1ccfdcf",
   "metadata": {},
   "source": [
    "#### Writing the dataset\n",
    "######  - [_Click here to move back to index_](#Similarity-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "160ca76a-ea05-49b2-b23d-8c0a0cffc013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\Overall_Similarity.csv\n",
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\Pairwise_Similarity.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data\\\\processed\\\\Pairwise_Similarity.csv'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data_Preprocessing import write_data\n",
    "\n",
    "# Save to processed\n",
    "write_data(similarity_df, 'Overall_Similarity.csv')\n",
    "write_data(similarity_top_df, 'Pairwise_Similarity.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
