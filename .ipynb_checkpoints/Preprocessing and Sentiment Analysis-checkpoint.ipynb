{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6824e4-1bda-4433-9d55-e28800550bd5",
   "metadata": {},
   "source": [
    "### Preprocessing and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204cd1b-8d60-4e84-bdc4-b08f3afa8e4e",
   "metadata": {},
   "source": [
    "> <sub>⚠️ **Note**: Internal links (like Table of Contents) work best when this notebook is opened in **Jupyter Notebook** or **nbviewer.org**.<br>\n",
    "> GitHub does **not support scrolling to sections** inside `.ipynb` files.</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc281c66-afbf-4525-8946-20643762e720",
   "metadata": {},
   "source": [
    "---\n",
    "###### Data Ingestion\n",
    "######  - [Reading the data set](#Reading-the-data-set)\n",
    "######  - [Preprocessing of the data](#Preprocessing-of-the-data)\n",
    "###### Sentiment Analysis\n",
    "######  - [Using Bing Liu Lexicon](#Using-Bing-Liu-Lexicon)\n",
    "######  - [Using LM dictionary](#Using-LM-dictionary)\n",
    "######  - [Using TextBlob](#Using-TextBlob)\n",
    "######  - [Using Vader](#Using-Vader)\n",
    "######  - [Using Obscene Words](#Using-Obscene-Words)\n",
    "###### Output Extraction\n",
    "######  - [Creating consolidated dataset](#Creating-consolidated-dataset)\n",
    "######  - [Writing the dataset](#Writing-the-dataset)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b582e45-456c-403c-af10-2a38e014dc12",
   "metadata": {},
   "source": [
    "#### Reading the data set\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53c848cc-7ede-4412-a534-ecf89a9ef981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5282d9a5-825f-4143-b4bc-f0e74e3f9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocessing import load_data, analyze_character_dialogues\n",
    "\n",
    "#Reading data dialogues of TV series\n",
    "\n",
    "series_1 = load_data('data/raw/friends_quotes.csv')\n",
    "series_2 = load_data('data/raw/Game_of_Thrones_Script.csv')\n",
    "series_3 = load_data('data/raw/Office Script by Characters.csv')\n",
    "series_4 = load_data('data/raw/1_10_seasons_tbbt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f806c3-b48e-4cf0-9112-a75ef86935e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 by Dialogue Length - Episode 01x02\n",
      "      character  total_characters  percent_of_total\n",
      "0         Ross              3802             27.95\n",
      "1       Rachel              2389             17.56\n",
      "2       Monica              1515             11.14\n",
      "3     Chandler              1284              9.44\n",
      "4   Mr. Geller               772              5.68\n",
      "5        Barry               747              5.49\n",
      "6       Phoebe               713              5.24\n",
      "7  Mrs. Geller               657              4.83\n",
      "8        Carol               582              4.28\n",
      "9         Joey               351              2.58\n",
      "\n",
      "Top 10 by Dialogue Rows - Episode 01x02\n",
      "      character  dialogue_lines  percent_of_total\n",
      "0         Ross              63             25.93\n",
      "1       Rachel              38             15.64\n",
      "2       Monica              28             11.52\n",
      "3        Carol              21              8.64\n",
      "4        Barry              16              6.58\n",
      "5     Chandler              16              6.58\n",
      "6       Phoebe              14              5.76\n",
      "7  Mrs. Geller              10              4.12\n",
      "8        Susan               9              3.70\n",
      "9         Joey               8              3.29\n",
      "\n",
      "Top 10 by Dialogue Length - Season 01\n",
      "     character  total_characters  percent_of_total\n",
      "0        Ross             56732             17.38\n",
      "1      Rachel             50063             15.34\n",
      "2    Chandler             47486             14.55\n",
      "3      Monica             44125             13.52\n",
      "4      Phoebe             34742             10.64\n",
      "5        Joey             34571             10.59\n",
      "6      Janice              2729              0.84\n",
      "7       Carol              2548              0.78\n",
      "8  Mr. Geller              2258              0.69\n",
      "9       Susan              2198              0.67\n",
      "\n",
      "Top 10 by Dialogue Rows - Season 01\n",
      "   character  dialogue_lines  percent_of_total\n",
      "0      Ross             919             15.37\n",
      "1    Monica             854             14.28\n",
      "2    Rachel             828             13.85\n",
      "3  Chandler             765             12.79\n",
      "4      Joey             613             10.25\n",
      "5    Phoebe             599             10.02\n",
      "6       All              88              1.47\n",
      "7     Carol              73              1.22\n",
      "8     Susan              56              0.94\n",
      "9   Chandle              51              0.85\n",
      "\n",
      "Top 10 by Dialogue Length - Overall\n",
      "   character  total_characters  percent_of_total\n",
      "0      Ross            556366             15.40\n",
      "1    Rachel            543281             15.04\n",
      "2      Joey            512975             14.20\n",
      "3  Chandler            494006             13.68\n",
      "4    Phoebe            465872             12.90\n",
      "5    Monica            465749             12.89\n",
      "6      Mike             19535              0.54\n",
      "7    Janice             15160              0.42\n",
      "8   Richard             12717              0.35\n",
      "9     David             10533              0.29\n",
      "\n",
      "Top 10 by Dialogue Rows - Overall\n",
      "   character  dialogue_lines  percent_of_total\n",
      "0    Rachel            8956             14.85\n",
      "1      Ross            8921             14.80\n",
      "2  Chandler            8180             13.57\n",
      "3    Monica            8175             13.56\n",
      "4      Joey            8016             13.30\n",
      "5    Phoebe            7261             12.04\n",
      "6      Mike             351              0.58\n",
      "7       All             330              0.55\n",
      "8   Richard             256              0.42\n",
      "9    Janice             214              0.35\n"
     ]
    }
   ],
   "source": [
    "# Initial analysis for series 1\n",
    "results = analyze_character_dialogues(series_1, show_overall=True, season='1', episode='2')\n",
    "for name, table in results.items():\n",
    "    print(f\"\\n{name}\\n\", table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2fa04b-d5f4-40de-9776-e975ed9b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 by Dialogue Length - Episode 01x02\n",
      "            character  total_characters  percent_of_total\n",
      "0   Tyrion Lannister              2538             13.87\n",
      "1   Robert Baratheon              2189             11.96\n",
      "2   Cersei Lannister              1476              8.07\n",
      "3       Eddard Stark              1420              7.76\n",
      "4           Jon Snow              1305              7.13\n",
      "5      Catelyn Stark              1240              6.78\n",
      "6             Doreah              1234              6.74\n",
      "7  Joffrey Lannister              1110              6.07\n",
      "8    Jaime Lannister               817              4.46\n",
      "9         Arya Stark               713              3.90\n",
      "\n",
      "Top 10 by Dialogue Rows - Episode 01x02\n",
      "             character  dialogue_lines  percent_of_total\n",
      "0        Eddard Stark              32             11.31\n",
      "1            Jon Snow              24              8.48\n",
      "2          Arya Stark              23              8.13\n",
      "3    Robert Baratheon              23              8.13\n",
      "4    Tyrion Lannister              21              7.42\n",
      "5       Catelyn Stark              21              7.42\n",
      "6    Cersei Lannister              19              6.71\n",
      "7   Joffrey Lannister              17              6.01\n",
      "8          Robb Stark              13              4.59\n",
      "9  Daenerys Targaryen              13              4.59\n",
      "\n",
      "Top 10 by Dialogue Length - Season 01\n",
      "             character  total_characters  percent_of_total\n",
      "0    Tyrion Lannister             17953              9.34\n",
      "1        Eddard Stark             16285              8.47\n",
      "2    Robert Baratheon             12212              6.35\n",
      "3       Petyr Baelish              8971              4.67\n",
      "4       Catelyn Stark              7437              3.87\n",
      "5    Cersei Lannister              7437              3.87\n",
      "6     Jaime Lannister              6542              3.40\n",
      "7               Varys              5912              3.08\n",
      "8            Jon Snow              5629              2.93\n",
      "9  Daenerys Targaryen              5153              2.68\n",
      "\n",
      "Top 10 by Dialogue Rows - Season 01\n",
      "             character  dialogue_lines  percent_of_total\n",
      "0        Eddard Stark             335             10.54\n",
      "1    Tyrion Lannister             212              6.67\n",
      "2       Catelyn Stark             138              4.34\n",
      "3            Jon Snow             136              4.28\n",
      "4  Daenerys Targaryen             126              3.96\n",
      "5    Robert Baratheon             118              3.71\n",
      "6    Cersei Lannister             117              3.68\n",
      "7       Petyr Baelish             112              3.52\n",
      "8          Arya Stark             102              3.21\n",
      "9         Sansa Stark              99              3.11\n",
      "\n",
      "Top 10 by Dialogue Length - Overall\n",
      "             character  total_characters  percent_of_total\n",
      "0    Tyrion Lannister            135307              9.13\n",
      "1    Cersei Lannister             75442              5.09\n",
      "2  Daenerys Targaryen             62807              4.24\n",
      "3            Jon Snow             62633              4.23\n",
      "4     Jaime Lannister             61131              4.12\n",
      "5         Sansa Stark             41514              2.80\n",
      "6       Petyr Baelish             37465              2.53\n",
      "7               Davos             35217              2.38\n",
      "8               Varys             33383              2.25\n",
      "9          Arya Stark             32767              2.21\n",
      "\n",
      "Top 10 by Dialogue Rows - Overall\n",
      "             character  dialogue_lines  percent_of_total\n",
      "0    Tyrion Lannister            1760              7.36\n",
      "1            Jon Snow            1133              4.74\n",
      "2  Daenerys Targaryen            1048              4.38\n",
      "3    Cersei Lannister            1005              4.20\n",
      "4     Jaime Lannister             945              3.95\n",
      "5         Sansa Stark             784              3.28\n",
      "6          Arya Stark             783              3.27\n",
      "7               Davos             528              2.21\n",
      "8       Theon Greyjoy             455              1.90\n",
      "9       Petyr Baelish             449              1.88\n"
     ]
    }
   ],
   "source": [
    "# Initial analysis for series 2\n",
    "results = analyze_character_dialogues(series_2, show_overall=True, season='1', episode='2')\n",
    "for name, table in results.items():\n",
    "    print(f\"\\n{name}\\n\", table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c3fdae-7e90-400a-a4fd-b8204d9981cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 by Dialogue Length - Episode 01x02\n",
      "    character  total_characters  percent_of_total\n",
      "0    Michael             12936             57.12\n",
      "1  Mr. Brown              3201             14.13\n",
      "2        Jim              2202              9.72\n",
      "3     Dwight              1975              8.72\n",
      "4        Pam               820              3.62\n",
      "5       Ryan               436              1.93\n",
      "6      Oscar               404              1.78\n",
      "7      Kevin               388              1.71\n",
      "8    Stanley               125              0.55\n",
      "9       Toby                85              0.38\n",
      "\n",
      "Top 10 by Dialogue Rows - Episode 01x02\n",
      "    character  dialogue_lines  percent_of_total\n",
      "0    Michael             103             34.68\n",
      "1  Mr. Brown              52             17.51\n",
      "2     Dwight              40             13.47\n",
      "3        Jim              35             11.78\n",
      "4        Pam              26              8.75\n",
      "5      Oscar              13              4.38\n",
      "6      Kevin               8              2.69\n",
      "7       Ryan               7              2.36\n",
      "8    Stanley               5              1.68\n",
      "9     Angela               4              1.35\n",
      "\n",
      "Top 10 by Dialogue Length - Season 01\n",
      "    character  total_characters  percent_of_total\n",
      "0    Michael             67009             51.23\n",
      "1     Dwight             19659             15.03\n",
      "2        Jim             15777             12.06\n",
      "3        Pam              7864              6.01\n",
      "4  Mr. Brown              3201              2.45\n",
      "5      Oscar              2234              1.71\n",
      "6       Katy              1930              1.48\n",
      "7        Jan              1876              1.43\n",
      "8       Ryan              1726              1.32\n",
      "9     Angela              1318              1.01\n",
      "\n",
      "Top 10 by Dialogue Rows - Season 01\n",
      "    character  dialogue_lines  percent_of_total\n",
      "0    Michael             642             32.16\n",
      "1     Dwight             326             16.33\n",
      "2        Jim             285             14.28\n",
      "3        Pam             219             10.97\n",
      "4       Katy              73              3.66\n",
      "5      Oscar              58              2.91\n",
      "6  Mr. Brown              52              2.61\n",
      "7       Ryan              52              2.61\n",
      "8        Jan              38              1.90\n",
      "9        Roy              35              1.75\n",
      "\n",
      "Top 10 by Dialogue Length - Overall\n",
      "   character  total_characters  percent_of_total\n",
      "0   Michael            942733             26.30\n",
      "1    Dwight            494455             13.79\n",
      "2       Jim            354374              9.89\n",
      "3      Andy            270647              7.55\n",
      "4       Pam            266867              7.44\n",
      "5    Angela             83609              2.33\n",
      "6     Kevin             80477              2.24\n",
      "7      Erin             75447              2.10\n",
      "8     Oscar             75420              2.10\n",
      "9      Ryan             75269              2.10\n",
      "\n",
      "Top 10 by Dialogue Rows - Overall\n",
      "   character  dialogue_lines  percent_of_total\n",
      "0   Michael           12141             20.27\n",
      "1    Dwight            7531             12.57\n",
      "2       Jim            6817             11.38\n",
      "3       Pam            5376              8.97\n",
      "4      Andy            3968              6.62\n",
      "5     Kevin            1708              2.85\n",
      "6    Angela            1695              2.83\n",
      "7     Oscar            1490              2.49\n",
      "8      Erin            1469              2.45\n",
      "9      Ryan            1379              2.30\n"
     ]
    }
   ],
   "source": [
    "# Initial analysis for series 3\n",
    "results = analyze_character_dialogues(series_3, show_overall=True, season='1', episode='2')\n",
    "for name, table in results.items():\n",
    "    print(f\"\\n{name}\\n\", table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820b1991-b351-433d-8113-f9eb65cf87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 by Dialogue Length - Episode 01x02\n",
      "       character  total_characters  percent_of_total\n",
      "0       Sheldon              5386             32.90\n",
      "1       Leonard              4989             30.47\n",
      "2         Penny              2635             16.09\n",
      "3        Howard              1057              6.46\n",
      "4         Scene               911              5.56\n",
      "5  (Internally)               299              1.83\n",
      "6           Raj               267              1.63\n",
      "7    (Entering)               137              0.84\n",
      "8          Him)               133              0.81\n",
      "9         Talk)                89              0.54\n",
      "\n",
      "Top 10 by Dialogue Rows - Episode 01x02\n",
      "       character  dialogue_lines  percent_of_total\n",
      "0       Leonard              83             33.47\n",
      "1       Sheldon              70             28.23\n",
      "2         Penny              41             16.53\n",
      "3        Howard              16              6.45\n",
      "4         Scene              11              4.44\n",
      "5           Raj               5              2.02\n",
      "6    (Entering)               3              1.21\n",
      "7          Off)               3              1.21\n",
      "8  (Internally)               3              1.21\n",
      "9         (Off)               2              0.81\n",
      "\n",
      "Top 10 by Dialogue Length - Season 01\n",
      "      character  total_characters  percent_of_total\n",
      "0      Sheldon             82596             31.90\n",
      "1      Leonard             61599             23.79\n",
      "2        Penny             34427             13.30\n",
      "3       Howard             24573              9.49\n",
      "4          Raj             14017              5.41\n",
      "5        Scene              8536              3.30\n",
      "6       Cooper              3668              1.42\n",
      "7       Lesley              3205              1.24\n",
      "8  Gablehouser              3154              1.22\n",
      "9        Missy              2654              1.03\n",
      "\n",
      "Top 10 by Dialogue Rows - Season 01\n",
      "      character  dialogue_lines  percent_of_total\n",
      "0      Leonard            1171             27.04\n",
      "1      Sheldon            1097             25.33\n",
      "2        Penny             663             15.31\n",
      "3       Howard             396              9.15\n",
      "4          Raj             237              5.47\n",
      "5        Scene             162              3.74\n",
      "6       Lesley              50              1.15\n",
      "7  Gablehouser              48              1.11\n",
      "8        Missy              46              1.06\n",
      "9       Cooper              42              0.97\n",
      "\n",
      "Top 10 by Dialogue Length - Overall\n",
      "     character  total_characters  percent_of_total\n",
      "0     Sheldon            942480             29.33\n",
      "1     Leonard            496391             15.45\n",
      "2       Penny            379630             11.82\n",
      "3      Howard            335469             10.44\n",
      "4         Raj            286676              8.92\n",
      "5         Amy            199537              6.21\n",
      "6  Bernadette            132133              4.11\n",
      "7       Scene             75545              2.35\n",
      "8      Stuart             38342              1.19\n",
      "9      Cooper             16927              0.53\n",
      "\n",
      "Top 10 by Dialogue Rows - Overall\n",
      "     character  dialogue_lines  percent_of_total\n",
      "0     Sheldon           11484             21.11\n",
      "1     Leonard            9638             17.71\n",
      "2       Penny            7477             13.74\n",
      "3      Howard            5737             10.54\n",
      "4         Raj            4576              8.41\n",
      "5         Amy            3419              6.28\n",
      "6       Scene            2850              5.24\n",
      "7  Bernadette            2636              4.85\n",
      "8      Stuart             726              1.33\n",
      "9       (Off)             218              0.40\n"
     ]
    }
   ],
   "source": [
    "# Initial analysis for series 4\n",
    "results = analyze_character_dialogues(series_4, show_overall=True, season='1', episode='2')\n",
    "for name, table in results.items():\n",
    "    print(f\"\\n{name}\\n\", table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168880b6-4362-48a0-8e7c-b7dc4a579d4b",
   "metadata": {},
   "source": [
    "#### Preprocessing of the data\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aef37116-c784-4b45-959d-1d7461ab02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocessing import preprocess_dialogue\n",
    "\n",
    "#Apply preprocessing to the dialogue column\n",
    "series_1['dialogue_preprocessed'] = series_1['dialogue'].apply(preprocess_dialogue)\n",
    "series_2['dialogue_preprocessed'] = series_2['dialogue'].apply(preprocess_dialogue)\n",
    "series_3['dialogue_preprocessed'] = series_3['dialogue'].apply(preprocess_dialogue)\n",
    "series_4['dialogue_preprocessed'] = series_4['dialogue'].apply(preprocess_dialogue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b6fe8e0-c087-4404-87a0-0ba6ca63125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release date</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>episode name</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>dialogue_length</th>\n",
       "      <th>dialogue_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>Waymar Royce</td>\n",
       "      <td>What do you expect? They're savages. One lot s...</td>\n",
       "      <td>01x01</td>\n",
       "      <td>137</td>\n",
       "      <td>expect savage one lot steal goat another lot k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>Will</td>\n",
       "      <td>I've never seen wildlings do a thing like this...</td>\n",
       "      <td>01x01</td>\n",
       "      <td>103</td>\n",
       "      <td>never seen wildlings thing like never seen thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>Waymar Royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>01x01</td>\n",
       "      <td>22</td>\n",
       "      <td>close get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>Will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "      <td>01x01</td>\n",
       "      <td>23</td>\n",
       "      <td>close man would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>Gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "      <td>01x01</td>\n",
       "      <td>32</td>\n",
       "      <td>head back wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  release date season episode      episode name     character  \\\n",
       "0    4/17/2011     01      01  Winter is Coming  Waymar Royce   \n",
       "1    4/17/2011     01      01  Winter is Coming          Will   \n",
       "2    4/17/2011     01      01  Winter is Coming  Waymar Royce   \n",
       "3    4/17/2011     01      01  Winter is Coming          Will   \n",
       "4    4/17/2011     01      01  Winter is Coming         Gared   \n",
       "\n",
       "                                            dialogue season_episode  \\\n",
       "0  What do you expect? They're savages. One lot s...          01x01   \n",
       "1  I've never seen wildlings do a thing like this...          01x01   \n",
       "2                             How close did you get?          01x01   \n",
       "3                            Close as any man would.          01x01   \n",
       "4                   We should head back to the wall.          01x01   \n",
       "\n",
       "   dialogue_length                              dialogue_preprocessed  \n",
       "0              137  expect savage one lot steal goat another lot k...  \n",
       "1              103  never seen wildlings thing like never seen thi...  \n",
       "2               22                                          close get  \n",
       "3               23                                    close man would  \n",
       "4               32                                     head back wall  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363099f9-a3f4-41e6-8c67-01f83dce2ddb",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e887ad-a17b-496b-a960-fbd66160b118",
   "metadata": {},
   "source": [
    "#### Using Bing Liu Lexicon\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0dcb5c3-9eb0-4bb5-8915-8f19976da8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sentiment_Analysis import count_pos_neg\n",
    "\n",
    "#Import Bing Liu's dictionary\n",
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "#Name the two positive and negative dictionary\n",
    "pos_list_BL=set(opinion_lexicon.positive())\n",
    "\n",
    "neg_list_BL=set(opinion_lexicon.negative())\n",
    "\n",
    "#Ddding the columns to the dataframe to count the positive, negative and net using BL dictionary\n",
    "#Using the function from above\n",
    "\n",
    "series_1['poscnt_BL'], series_1['negcnt_BL'], series_1['netcnt_BL'] = count_pos_neg(series_1['dialogue'], pos_list_BL, neg_list_BL)\n",
    "series_2['poscnt_BL'], series_2['negcnt_BL'], series_2['netcnt_BL'] = count_pos_neg(series_2['dialogue'], pos_list_BL, neg_list_BL)\n",
    "series_3['poscnt_BL'], series_3['negcnt_BL'], series_3['netcnt_BL'] = count_pos_neg(series_3['dialogue'], pos_list_BL, neg_list_BL)\n",
    "series_4['poscnt_BL'], series_4['negcnt_BL'], series_4['netcnt_BL'] = count_pos_neg(series_4['dialogue'], pos_list_BL, neg_list_BL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd328e7e-5750-4ff4-9340-404beed6044a",
   "metadata": {},
   "source": [
    "#### Using LM dictionary\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d997d763-a4db-460d-99f5-43cec9686143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sentiment_Analysis import read_local_dictionary\n",
    "\n",
    "#loading the text file into dictionary\n",
    "pos_list_LM = read_local_dictionary('data/raw/positive-words-LM.txt')\n",
    "\n",
    "neg_list_LM = read_local_dictionary('data/raw/negative-words-LM.txt')\n",
    "\n",
    "#Ddding the columns to the dataframe to count the positive, negative and net using LM dictionary\n",
    "#Using the function from above\n",
    "\n",
    "series_1['poscnt_LM'], series_1['negcnt_LM'], series_1['netcnt_LM'] = count_pos_neg(series_1['dialogue'], pos_list_LM, neg_list_LM)\n",
    "series_2['poscnt_LM'], series_2['negcnt_LM'], series_2['netcnt_LM'] = count_pos_neg(series_2['dialogue'], pos_list_LM, neg_list_LM)\n",
    "series_3['poscnt_LM'], series_3['negcnt_LM'], series_3['netcnt_LM'] = count_pos_neg(series_3['dialogue'], pos_list_LM, neg_list_LM)\n",
    "series_4['poscnt_LM'], series_4['negcnt_LM'], series_4['netcnt_LM'] = count_pos_neg(series_4['dialogue'], pos_list_LM, neg_list_LM)\n",
    "\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9355f-0a12-4b3e-9c6f-a4f86ad50f28",
   "metadata": {},
   "source": [
    "#### Using TextBlob\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01ecd74d-d82a-4382-af30-d939ccb22535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "# or, more safely, only convert non-null values\n",
    "series_2[\"dialogue\"] = series_2[\"dialogue\"].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
    "series_4[\"dialogue\"] = series_4[\"dialogue\"].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
    "\n",
    "#Mapping the sentiment scores and adding the new column for the score\n",
    "series_1[\"score_TextBlob\"] = series_1[\"dialogue\"].str.lower().map(lambda x:TextBlob(x).sentiment.polarity)\n",
    "series_2[\"score_TextBlob\"] = series_2[\"dialogue\"].str.lower().map(lambda x:TextBlob(x).sentiment.polarity)\n",
    "series_3[\"score_TextBlob\"] = series_3[\"dialogue\"].str.lower().map(lambda x:TextBlob(x).sentiment.polarity)\n",
    "series_4[\"score_TextBlob\"] = series_4[\"dialogue\"].str.lower().map(lambda x:TextBlob(x).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db95fc0-2657-4f04-a1ee-fb8a7006cce8",
   "metadata": {},
   "source": [
    "#### Using Vader\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65f204fa-fb86-419d-9439-06a9df643194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sentiment_Analysis import vader_analyzer\n",
    "\n",
    "series_1 = vader_analyzer(series_1)\n",
    "series_2 = vader_analyzer(series_2)\n",
    "series_3 = vader_analyzer(series_3)\n",
    "series_4 = vader_analyzer(series_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136a800-860d-4f1c-8056-924c2e49b584",
   "metadata": {},
   "source": [
    "#### Using Obscene Words\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4dce8a1-e9d6-49a1-9ddb-c934fcdcc7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sentiment_Analysis import count_obs\n",
    "\n",
    "#loading the text file into dictionary\n",
    "obscene_words = read_local_dictionary('data/raw/obscene_words.txt')\n",
    "\n",
    "#Ddding the columns to the dataframe to count the obscene words\n",
    "#Using the function from above\n",
    "\n",
    "series_1['obscene_words_count'] = count_obs(series_1['dialogue'], obscene_words)\n",
    "series_2['obscene_words_count'] = count_obs(series_2['dialogue'], obscene_words)\n",
    "series_3['obscene_words_count'] = count_obs(series_3['dialogue'], obscene_words)\n",
    "series_4['obscene_words_count'] = count_obs(series_4['dialogue'], obscene_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a1d40-8623-4812-b994-c7ac61da99ac",
   "metadata": {},
   "source": [
    "#### Creating consolidated dataset\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e38cbff-7653-4ef8-917d-67e8e6b00416",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1['Series_Name'] = 'Friends'\n",
    "series_2['Series_Name'] = 'Game of Thrones'\n",
    "series_3['Series_Name'] = 'The Office'\n",
    "series_4['Series_Name'] = 'The Big Bang Theory'\n",
    "\n",
    "common_columns = list(set(series_1.columns) & set(series_2.columns) & set(series_3.columns) & set(series_4.columns))\n",
    "common_columns\n",
    "\n",
    "concatenated_df = pd.concat([series_1[common_columns], series_2[common_columns], series_3[common_columns], \n",
    "                             series_4[common_columns]], ignore_index=True)\n",
    "\n",
    "# Multiply specified columns by 'dialogue_length' for weighted mean\n",
    "cols_to_multiply = ['negcnt_BL', 'poscnt_LM', 'poscnt_BL', 'obscene_words_count', 'negscore_Vader', \n",
    "                    'score_TextBlob', 'negcnt_LM', 'posscore_Vader', 'compound_vader']\n",
    "for col in cols_to_multiply:\n",
    "    if col in concatenated_df.columns:  # Check if the column exists\n",
    "        concatenated_df[f'SumProd_{col}'] = concatenated_df[col] * concatenated_df['dialogue_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1878e0e-5bd7-410c-8c45-69ae1dc0ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a 'Top_6_Flag' column showing top 6 characters for each season of a series by Dialogue length\n",
    "\n",
    "grouped = (\n",
    "    concatenated_df.groupby(['Series_Name', 'season', 'character'], as_index=False)\n",
    "      .agg({'dialogue_length': 'sum'})\n",
    ")\n",
    "\n",
    "# Rank characters by Dialogue Length within each Series-Season\n",
    "grouped['Rank'] = grouped.groupby(['Series_Name', 'season'])['dialogue_length'] \\\n",
    "                         .rank(method='first', ascending=False)\n",
    "\n",
    "# Flag top 6\n",
    "grouped['Top_6_Flag'] = grouped['Rank'].apply(lambda x: 'Top 6' if x <= 6 else 'Other')\n",
    "\n",
    "# If you want to merge back to the original dataframe:\n",
    "concatenated_df = concatenated_df.merge(grouped[['Series_Name', 'season', 'character', 'Top_6_Flag']], \n",
    "              on=['Series_Name', 'season', 'character'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f80d70-99c0-4aea-a6c4-cde9ea3bac00",
   "metadata": {},
   "source": [
    "#### Writing the dataset\n",
    "######  - [_Click here to move back to index_](#Preprocessing-and-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92f0208f-8c03-4cb3-9616-5e2d901298dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\Data_For_Tableau.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data\\\\processed\\\\Data_For_Tableau.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data_Preprocessing import write_data\n",
    "\n",
    "# Save to processed\n",
    "write_data(concatenated_df, 'Data_For_Tableau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25e8bd72-eb9b-459d-84be-c5820ba5f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\processed_series_1.csv\n",
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\processed_series_2.csv\n",
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\processed_series_3.csv\n",
      "Data written to: C:\\Users\\utkar\\Desktop\\PyCharm Projects Spring\\Natural Language Processing\\data\\processed\\processed_series_4.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data\\\\processed\\\\processed_series_4.csv'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_data(series_1, 'processed_series_1.csv')\n",
    "write_data(series_2, 'processed_series_2.csv')\n",
    "write_data(series_3, 'processed_series_3.csv')\n",
    "write_data(series_4, 'processed_series_4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
